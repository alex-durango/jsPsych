<!DOCTYPE html>
<html>
<head>
    <script src="../jspsych.js"></script>
    <script src="../plugins/jspsych-image-audio-response.js"></script>
    <link rel="stylesheet" href="../css/jspsych.css"></link>
</head>
<body></body>
<script>

    // By default, the audio will be saved as a JSON/CSV-friendly base64 string and will need to be converted back to
    // an audio file offline. This can be done using existing functions in R (base64enc package) or Python (base64
    // library). You can also test the conversion using an online base64-to-audio converter like this one: 
    // https://base64.guru/converter/decode/audio (useful for testing but should not be used with real particpant data).
    // The default postprocessing function can be overwritten by passing a custom function to the 'postprocessing' 
    // parameter. This provides the option to save the data as an audio file rather than a string.
    // See the plugin documentation for an example of a custom function that saves the audio data to a server. 

    var timeline = [];

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_1.jpg',
        prompt: "<p>What emotion is this person showing?</p>"+
        "<p>(Allow playback = true)</p>",
        buffer_length: 2000,
        stimulus_width: 300
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/sad_face_1.jpg',
        prompt: "<p>What emotion is this person showing?</p>"+
        "<p>(Wait for mic approval = false, allow playback = true)</p>",
        wait_for_mic_approval: false,
        buffer_length: 2000,
        stimulus_width: 300
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_2.jpg',
        prompt: "<p>What emotion is this person showing?</p>"+
        "<p>(Wait for mic approval = false, allow playback = false,<br>"+
        "recording indicator type = 2 - see bottom right of screen)</p>",
        wait_for_mic_approval: false,
        allow_playback: false,
        stimulus_width: 300,
        recording_indicator_type: 2
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/sad_face_2.jpg',
        prompt: "<p>What emotion is this person showing?</p>"+
        "<p>(Wait for mic approval = true, allow playback = true,<br>"+
        "recording indicator type = 3 - custom HTML, centered below stimulus/prompt and above playback controls)</p>",
        stimulus_width: 300,
        recording_indicator_type: 3,
        recording_on_indicator: '<p style="color: green; font-weight: bold;">TALK NOW!</p>',
        recording_off_indicator: '<p style="color: gray; font-weight: bold;">Not recording.</p>'
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_3.jpg',
        prompt: "<p>What emotion is this person showing?</p>"+
        "<p>(Wait for mic approval = false, allow playback = true,<br>"+
        "recording indicator type = 4 - custom HTML/positioning, does not affect stimulus/prompt/playback positioning)</p>",
        stimulus_width: 300,
        recording_indicator_type: 4,
        recording_on_indicator: '<p style="position: fixed; top: 10px; left: 50%; transform: translate(-50%, 0%); font-size: 30px; color: red; font-weight: bold;">RECORDING!</p>',
        recording_off_indicator: '<p style="position: fixed; top: 10px; left: 50%; transform: translate(-50%, 0%); font-size: 30px; color: gray; font-weight: bold;">Not recording.</p>'
    });

    jsPsych.init({
        timeline: timeline,
        on_finish: function(){
            jsPsych.data.displayData();
        }
    });

</script>
</html>
