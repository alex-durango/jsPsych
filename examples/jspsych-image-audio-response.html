<!DOCTYPE html>
<html>
<head>
    <script src="../jspsych.js"></script>
    <script src="../plugins/jspsych-image-audio-response.js"></script>
    <link rel="stylesheet" href="../css/jspsych.css"></link>
</head>
<body></body>
<script>

    // By default, the audio will be saved as a JSON/CSV-friendly base64 string and will need to be converted back to
    // an audio file offline. This can be done using existing functions in R (base64enc package) or Python (base64
    // library). You can also test the conversion using an online base64-to-audio converter like this one: 
    // https://base64.guru/converter/decode/audio (useful for testing but should not be used with real particpant data).
    // The default postprocessing function can be overwritten by passing a custom function to the 'postprocessing' 
    // parameter. This provides the option to save the data as an audio file rather than a string.
    // See the plugin documentation for more details. 

    let timeline = [];

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_1.jpg',
        prompt: "<p>What emotion is this person showing?</p><p>(Wait for mic approval = true, image disappears after 1s, allow playback = false)</p>",
        allow_playback: false,
        stimulus_duration: 1000,
        buffer_length: 2000,
        wait_for_mic_approval: true,
        stimulus_width: 300
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/sad_face_1.jpg',
        prompt: "<p>What emotion is this person showing?</p><p>(Wait for mic approval = false, allow playback = true)</p>",
        allow_playback: true,
        buffer_length: 2000,
        stimulus_width: 300
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/happy_face_2.jpg',
        response_ends_trial: true,
        prompt: "<p>What emotion is this person showing?</p><p>(Type 2 recording indicators - see bottom right of screen)</p>",
        stimulus_width: 300,
        recording_indicator_type: 2
    });

    timeline.push({
        type: 'image-audio-response',
        stimulus: 'img/sad_face_2.jpg',
        response_ends_trial: true,
        prompt: "<p>What emotion is this person showing?</p><p>(Type 3 recording indicators - custom HTML)</p>",
        stimulus_width: 300,
        recording_indicator_type: 3,
        recording_on_indicator: '<span style="font-size: 25px; color: green; font-weight: bold;">TALK NOW!</span>',
        recording_off_indicator: '<span style="font-size: 25px; color: gray;">not recording</span>'
    });

    jsPsych.init({
        timeline: timeline,
        on_finish: function(){
            jsPsych.data.displayData();
        }
    });

</script>
</html>
